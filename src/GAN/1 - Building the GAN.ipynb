{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/gan.py\n",
    "https://stackoverflow.com/questions/40994583/how-to-implement-tensorflows-next-batch-for-own-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_labels_dict(data_path):\n",
    "    labels_dict = {}\n",
    "    with open(data_path + 'sci_labels.csv', 'r') as f:\n",
    "        file = csv.reader(f)\n",
    "        for row in file:\n",
    "            labels_dict[row[0]] = row[1]\n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def get_features_labels(root, labels_dict):\n",
    "    corpus = [] # each row is a string formed from all messages in a conversations\n",
    "    labels = [] # each row is 0 or 1, corresponds to label for same row in corpus\n",
    "\n",
    "    for conversation in root:\n",
    "        string = \" \"\n",
    "        for message in conversation:\n",
    "            text = message.find('text').text\n",
    "            if text is not None:\n",
    "                string = string + \"\\r\\n\" + text \n",
    "        corpus.append(string)\n",
    "        labels.append(int(labels_dict[conversation.get('id')]))\n",
    "    return corpus, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../../data/svm_training_data/'\n",
    "training_xml = ET.parse(train_data_path + 'training_data.xml')\n",
    "train_root = training_xml.getroot()\n",
    "\n",
    "test_data_path = '../../data/svm_test_data/'\n",
    "test_data_src = '../../data/pan12-sexual-predator-identification-test-corpus-2012-05-21/'\n",
    "test_xml = ET.parse(test_data_src + 'pan12-sexual-predator-identification-test-corpus-2012-05-17.xml')\n",
    "test_root = test_xml.getroot()\n",
    "\n",
    "train_corpus, train_labels = get_features_labels(train_root, get_labels_dict(train_data_path))\n",
    "test_corpus, test_labels = get_features_labels(test_root, get_labels_dict(test_data_path))\n",
    "\n",
    "train_corpus_norm = []\n",
    "train_corpus_susp = []\n",
    "train_labels_norm = []\n",
    "train_labels_susp = []\n",
    "for index in range(len(train_corpus)):\n",
    "    if train_labels[index] == 1:\n",
    "        train_corpus_susp.append(train_corpus[index])\n",
    "        train_labels_susp.append(train_labels[index])\n",
    "    else:\n",
    "        train_corpus_norm.append(train_corpus[index])\n",
    "        train_labels_norm.append(train_labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.44709805\n",
      "-0.96498847\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import scipy\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "_ = vectorizer.fit_transform(train_corpus)\n",
    "X_train_norm = vectorizer.transform(train_corpus_norm)\n",
    "X_train_susp = vectorizer.transform(train_corpus_susp)\n",
    "X_test = vectorizer.transform(test_corpus)\n",
    "\n",
    "X_train_norm = scipy.sparse.csr_matrix(X_train_norm, dtype=np.float32)\n",
    "y_train_norm = np.array(train_labels_norm)\n",
    "X_train_susp = scipy.sparse.csr_matrix(X_train_susp, dtype=np.float32)\n",
    "y_train_susp = np.array(train_labels_susp)\n",
    "X_test = scipy.sparse.csr_matrix(X_test, dtype=np.float32)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "print(np.min(X_train_norm[:][0]))\n",
    "print(np.max(X_train_norm[:][0]))\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train_norm)\n",
    "X_train_susp = scaler.fit_transform(X_train_susp)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_train_norm.data -= 0.5\n",
    "X_train_susp.data -= 0.5\n",
    "X_test.data -= 0.5\n",
    "X_train_norm.data *= 2\n",
    "X_train_susp.data *= 2\n",
    "X_test.data *= 2\n",
    "\n",
    "print(np.min(X_train_norm[:][0]))\n",
    "print(np.max(X_train_norm[:][0]))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=87)\n",
    "# print(\"Train data shape:{}\\r\\nTest data shape:{}\".format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0010184544\n"
     ]
    }
   ],
   "source": [
    "# print(X_train_norm[:][0])\n",
    "print(np.mean(X_train_norm[:][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121394\n",
      "WARNING:tensorflow:From c:\\ce 3a\\cs 480\\onlinegrooming\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Generative Adversarial Networks (GAN).\n",
    "Using generative adversarial networks (GAN) to generate digit images from a\n",
    "noise distribution.\n",
    "References:\n",
    "    - Generative adversarial nets. I Goodfellow, J Pouget-Abadie, M Mirza,\n",
    "    B Xu, D Warde-Farley, S Ozair, Y. Bengio. Advances in neural information\n",
    "    processing systems, 2672-2680.\n",
    "    - Understanding the difficulty of training deep feedforward neural networks.\n",
    "    X Glorot, Y Bengio. Aistats 9, 249-256\n",
    "Links:\n",
    "    - [GAN Paper](https://arxiv.org/pdf/1406.2661.pdf).\n",
    "    - [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    - [Xavier Glorot Init](www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.../AISTATS2010_Glorot.pdf).\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import MNIST data\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "# Training Params\n",
    "num_steps = 10\n",
    "batch_size = 100 #128\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# Network Params\n",
    "image_dim = X_train_norm.shape[1] #784 # 28*28 pixels\n",
    "gen_hidden_dim = 10 #256\n",
    "disc_hidden_dim = 10 #256\n",
    "noise_dim = X_train_norm.shape[1] # 100 # Noise data points\n",
    "print(X_train_norm.shape[1])\n",
    "\n",
    "# A custom initialization (see Xavier Glorot init)\n",
    "def glorot_init(shape):\n",
    "    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'gen_hidden1': tf.Variable(glorot_init([noise_dim, gen_hidden_dim])),\n",
    "    'gen_out': tf.Variable(glorot_init([gen_hidden_dim, image_dim])),\n",
    "    'disc1_hidden1': tf.Variable(glorot_init([image_dim, disc_hidden_dim])),\n",
    "    'disc1_out': tf.Variable(glorot_init([disc_hidden_dim, 1])),\n",
    "    'disc2_hidden1': tf.Variable(glorot_init([image_dim, disc_hidden_dim])),\n",
    "    'disc2_out': tf.Variable(glorot_init([disc_hidden_dim, 1])),\n",
    "}\n",
    "biases = {\n",
    "    'gen_hidden1': tf.Variable(tf.zeros([gen_hidden_dim])),\n",
    "    'gen_out': tf.Variable(tf.zeros([image_dim])),\n",
    "    'disc1_hidden1': tf.Variable(tf.zeros([disc_hidden_dim])),\n",
    "    'disc1_out': tf.Variable(tf.zeros([1])),\n",
    "    'disc2_hidden1': tf.Variable(tf.zeros([disc_hidden_dim])),\n",
    "    'disc2_out': tf.Variable(tf.zeros([1])),\n",
    "}\n",
    "\n",
    "\n",
    "# Generator\n",
    "def generator(x):\n",
    "    hidden_layer = tf.matmul(x, weights['gen_hidden1'])\n",
    "    hidden_layer = tf.add(hidden_layer, biases['gen_hidden1'])\n",
    "    hidden_layer = tf.nn.relu(hidden_layer)\n",
    "    out_layer = tf.matmul(hidden_layer, weights['gen_out'])\n",
    "    out_layer = tf.add(out_layer, biases['gen_out'])\n",
    "    out_layer = tf.nn.sigmoid(out_layer)\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "def discriminator_SCI(x): # is D in paper\n",
    "    hidden_layer = tf.matmul(x, weights['disc1_hidden1'])\n",
    "    hidden_layer = tf.add(hidden_layer, biases['disc1_hidden1'])\n",
    "    hidden_layer = tf.nn.relu(hidden_layer)\n",
    "    out_layer = tf.matmul(hidden_layer, weights['disc1_out'])\n",
    "    out_layer = tf.add(out_layer, biases['disc1_out'])\n",
    "    out_layer = tf.nn.sigmoid(out_layer)\n",
    "    return out_layer\n",
    "\n",
    "def discriminator_gvr(x): # is D prime in paper, discriminator_generated_vs_real\n",
    "    hidden_layer = tf.matmul(x, weights['disc2_hidden1'])\n",
    "    hidden_layer = tf.add(hidden_layer, biases['disc2_hidden1'])\n",
    "    hidden_layer = tf.nn.relu(hidden_layer)\n",
    "    out_layer = tf.matmul(hidden_layer, weights['disc2_out'])\n",
    "    out_layer = tf.add(out_layer, biases['disc2_out'])\n",
    "    out_layer = tf.nn.sigmoid(out_layer)\n",
    "    return out_layer\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , data.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i].toarray() for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    data_shuffle = scipy.sparse.csr_matrix(data_shuffle)\n",
    "    print(data_shuffle.shape)\n",
    "    return data_shuffle, labels_shuffle\n",
    "#     print(len(data_shuffle[0]))\n",
    "#     return scipy.sparse.csr_matrix(data_shuffle), np.asarray(labels_shuffle)\n",
    "#     return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13802, 121394)\n",
      "(901, 121394)\n"
     ]
    }
   ],
   "source": [
    "# Build Networks\n",
    "# Network Inputs\n",
    "gen_input = tf.placeholder(tf.float32, shape=[None, noise_dim], name='input_noise')\n",
    "# disc_input_normal = tf.placeholder(tf.float32, shape=[None, image_dim], name='disc_input_normal')\n",
    "# disc_input_real_susp = tf.placeholder(tf.float32, shape=[None, image_dim], name='disc_input_real_susp')\n",
    "# # disc_input_fake_susp = tf.placeholder(tf.float32, shape=[None, image_dim], name='disc_input_fake_susp')\n",
    "\n",
    "# tf.float32\n",
    "# https://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428\n",
    "# x_norm = tf.sparse_placeholder(tf.float64)\n",
    "# x_susp = tf.sparse_placeholder(tf.float64)\n",
    "x_norm, x_susp = tf.placeholder(tf.float32, shape=[None, image_dim]), tf.placeholder(tf.float32, shape=[None, image_dim])\n",
    "dataset_norm = tf.data.Dataset.from_tensor_slices(x_norm).repeat().batch(batch_size)\n",
    "dataset_susp = tf.data.Dataset.from_tensor_slices(x_susp).repeat().batch(batch_size)\n",
    "# train_data = (np.random.sample((100,2)), np.random.sample((100,1)))\n",
    "# test_data = (np.array([[1,2]]), np.array([[0]]))\n",
    "iter_norm = dataset_norm.make_initializable_iterator()\n",
    "iter_susp = dataset_susp.make_initializable_iterator()\n",
    "features_norm = iter_norm.get_next()\n",
    "features_susp = iter_susp.get_next()\n",
    "\n",
    "# Build Generator Network\n",
    "# gen_sample_pre = generator(features_susp)\n",
    "gen_sample_pre = generator(gen_input)\n",
    "gen_sample = generator(gen_input)\n",
    "\n",
    "# Build 2 Discriminator Networks (one from noise input, one from generated samples)\n",
    "# disc_SCI_normal = discriminator_SCI(disc_input_normal)\n",
    "# disc_SCI_susp_real = discriminator_SCI(disc_input_real_susp)\n",
    "# disc_SCI_susp_fake = discriminator_SCI(gen_sample)\n",
    "# disc_gvr_real = discriminator_gvr(disc_input_real_susp)\n",
    "# disc_gvr_fake = discriminator_gvr(gen_sample)\n",
    "\n",
    "disc_SCI_normal = discriminator_SCI(features_norm)\n",
    "disc_SCI_susp_real = discriminator_SCI(features_susp)\n",
    "disc_SCI_susp_fake = discriminator_SCI(gen_sample)\n",
    "disc_gvr_real = discriminator_gvr(features_susp)\n",
    "disc_gvr_fake = discriminator_gvr(gen_sample)\n",
    "\n",
    "\n",
    "# Build Loss\n",
    "gen_loss_pre = tf.losses.mean_squared_error(features_susp, gen_sample_pre)\n",
    "gen_loss = -tf.reduce_mean(tf.log(disc_SCI_susp_fake + 1e-8) + tf.log(disc_gvr_fake + 1e-8))\n",
    "# disc_SCI_loss = -tf.reduce_mean(tf.log(disc_SCI_normal + 1e-8) + tf.log(1. - disc_SCI_susp_real + 1e-8) + tf.log(1. - disc_SCI_susp_fake + 1e-8))\n",
    "disc_SCI_loss = -tf.reduce_mean(tf.log(disc_SCI_normal + 1e-8) + tf.log(1. - disc_SCI_susp_real + 1e-8))\n",
    "disc_gvr_loss = -tf.reduce_mean(tf.log(disc_gvr_real + 1e-8) + tf.log(1. - disc_gvr_fake + 1e-8))\n",
    "\n",
    "# Build Optimizers\n",
    "optimizer_gen_pre = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer_gen = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer_disc = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# Training Variables for each optimizer\n",
    "# By default in TensorFlow, all variables are updated by each optimizer, so we\n",
    "# need to precise for each one of them the specific variables to update.\n",
    "# Generator Network Variables\n",
    "gen_vars = [weights['gen_hidden1'], weights['gen_out'],\n",
    "            biases['gen_hidden1'], biases['gen_out']]\n",
    "# Discriminator Network Variables\n",
    "disc_SCI_vars = [weights['disc1_hidden1'], weights['disc1_out'],\n",
    "            biases['disc1_hidden1'], biases['disc1_out']]\n",
    "disc_gvr_vars = [weights['disc2_hidden1'], weights['disc2_out'],\n",
    "            biases['disc2_hidden1'], biases['disc2_out']]\n",
    "\n",
    "# Create training operations\n",
    "train_gen_pre = optimizer_gen_pre.minimize(gen_loss_pre, var_list=gen_vars)\n",
    "train_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\n",
    "train_disc_SCI = optimizer_disc.minimize(disc_SCI_loss, var_list=disc_SCI_vars)\n",
    "train_disc_gvr = optimizer_disc.minimize(disc_gvr_loss, var_list=disc_gvr_vars)\n",
    "\n",
    "print(X_train_norm.shape)\n",
    "print(X_train_susp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining of generator starting.\n",
      "Step 1: Generator Loss: 0.279664\n",
      "Step 2: Generator Loss: 0.280260\n",
      "Step 3: Generator Loss: 0.280477\n",
      "Step 4: Generator Loss: 0.283691\n",
      "Step 5: Generator Loss: 0.279317\n",
      "Step 6: Generator Loss: 0.280007\n",
      "Step 7: Generator Loss: 0.279862\n",
      "Step 8: Generator Loss: 0.281284\n",
      "Step 9: Generator Loss: 0.277914\n",
      "Step 10: Generator Loss: 0.278026\n",
      "Step 11: Generator Loss: 0.279731\n",
      "Step 12: Generator Loss: 0.276324\n",
      "Step 13: Generator Loss: 0.280012\n",
      "Step 14: Generator Loss: 0.280907\n",
      "Step 15: Generator Loss: 0.277576\n",
      "Step 16: Generator Loss: 0.278840\n",
      "Step 17: Generator Loss: 0.277607\n",
      "Step 18: Generator Loss: 0.277580\n",
      "Step 19: Generator Loss: 0.278943\n",
      "Step 20: Generator Loss: 0.277178\n",
      "Step 21: Generator Loss: 0.278500\n",
      "Step 22: Generator Loss: 0.279537\n",
      "Step 23: Generator Loss: 0.277930\n",
      "Step 24: Generator Loss: 0.276545\n",
      "Step 25: Generator Loss: 0.275696\n",
      "Step 26: Generator Loss: 0.276830\n",
      "Step 27: Generator Loss: 0.275138\n",
      "Step 28: Generator Loss: 0.276137\n",
      "Step 29: Generator Loss: 0.277222\n",
      "Step 30: Generator Loss: 0.278431\n",
      "Step 31: Generator Loss: 0.271894\n",
      "Step 32: Generator Loss: 0.275350\n",
      "Step 33: Generator Loss: 0.273197\n",
      "Step 34: Generator Loss: 0.273090\n",
      "Step 35: Generator Loss: 0.273999\n",
      "Step 36: Generator Loss: 0.274857\n",
      "Step 37: Generator Loss: 0.273790\n",
      "Step 38: Generator Loss: 0.274233\n",
      "Step 39: Generator Loss: 0.273722\n",
      "Step 40: Generator Loss: 0.272188\n",
      "Step 41: Generator Loss: 0.273757\n",
      "Step 42: Generator Loss: 0.272743\n",
      "Step 43: Generator Loss: 0.276336\n",
      "Step 44: Generator Loss: 0.270276\n",
      "Step 45: Generator Loss: 0.271849\n",
      "Step 46: Generator Loss: 0.272224\n",
      "Step 47: Generator Loss: 0.273548\n",
      "Step 48: Generator Loss: 0.273025\n",
      "Step 49: Generator Loss: 0.274112\n",
      "Step 50: Generator Loss: 0.275061\n",
      "Step 51: Generator Loss: 0.271307\n",
      "Step 52: Generator Loss: 0.275232\n",
      "Step 53: Generator Loss: 0.271548\n",
      "Step 54: Generator Loss: 0.273191\n",
      "Step 55: Generator Loss: 0.273345\n",
      "Step 56: Generator Loss: 0.268227\n",
      "Step 57: Generator Loss: 0.272128\n",
      "Step 58: Generator Loss: 0.271780\n",
      "Step 59: Generator Loss: 0.270466\n",
      "Step 60: Generator Loss: 0.270137\n",
      "Step 61: Generator Loss: 0.269337\n",
      "Step 62: Generator Loss: 0.274551\n",
      "Step 63: Generator Loss: 0.270280\n",
      "Step 64: Generator Loss: 0.270636\n",
      "Step 65: Generator Loss: 0.268670\n",
      "Step 66: Generator Loss: 0.266781\n",
      "Step 67: Generator Loss: 0.271099\n",
      "Step 68: Generator Loss: 0.268786\n",
      "Step 69: Generator Loss: 0.268999\n",
      "Step 70: Generator Loss: 0.269668\n",
      "Step 71: Generator Loss: 0.267667\n",
      "Step 72: Generator Loss: 0.269977\n",
      "Step 73: Generator Loss: 0.271807\n",
      "Step 74: Generator Loss: 0.268023\n",
      "Step 75: Generator Loss: 0.265212\n",
      "Step 76: Generator Loss: 0.269988\n",
      "Step 77: Generator Loss: 0.266721\n",
      "Step 78: Generator Loss: 0.266959\n",
      "Step 79: Generator Loss: 0.268135\n",
      "Step 80: Generator Loss: 0.268233\n",
      "Step 81: Generator Loss: 0.268145\n",
      "Step 82: Generator Loss: 0.266644\n",
      "Step 83: Generator Loss: 0.268801\n",
      "Step 84: Generator Loss: 0.265907\n",
      "Step 85: Generator Loss: 0.268687\n",
      "Step 86: Generator Loss: 0.268648\n",
      "Step 87: Generator Loss: 0.265139\n",
      "Step 88: Generator Loss: 0.267488\n",
      "Step 89: Generator Loss: 0.267229\n",
      "Step 90: Generator Loss: 0.266609\n",
      "Step 91: Generator Loss: 0.263587\n",
      "Step 92: Generator Loss: 0.264175\n",
      "Step 93: Generator Loss: 0.267842\n",
      "Step 94: Generator Loss: 0.264570\n",
      "Step 95: Generator Loss: 0.265560\n",
      "Step 96: Generator Loss: 0.265312\n",
      "Step 97: Generator Loss: 0.264388\n",
      "Step 98: Generator Loss: 0.263816\n",
      "Step 99: Generator Loss: 0.265883\n",
      "Step 100: Generator Loss: 0.264278\n",
      "Step 101: Generator Loss: 0.264795\n",
      "Step 102: Generator Loss: 0.265789\n",
      "Step 103: Generator Loss: 0.265559\n",
      "Step 104: Generator Loss: 0.265226\n",
      "Step 105: Generator Loss: 0.261747\n",
      "Step 106: Generator Loss: 0.262418\n",
      "Step 107: Generator Loss: 0.262576\n",
      "Step 108: Generator Loss: 0.263276\n",
      "Step 109: Generator Loss: 0.262428\n",
      "Step 110: Generator Loss: 0.262920\n",
      "Step 111: Generator Loss: 0.265410\n",
      "Step 112: Generator Loss: 0.261867\n",
      "Step 113: Generator Loss: 0.261090\n",
      "Step 114: Generator Loss: 0.260577\n",
      "Step 115: Generator Loss: 0.260937\n",
      "Step 116: Generator Loss: 0.262544\n",
      "Step 117: Generator Loss: 0.262021\n",
      "Step 118: Generator Loss: 0.261706\n",
      "Step 119: Generator Loss: 0.259966\n",
      "Step 120: Generator Loss: 0.260911\n",
      "Step 121: Generator Loss: 0.262457\n",
      "Step 122: Generator Loss: 0.258767\n",
      "Step 123: Generator Loss: 0.260182\n",
      "Step 124: Generator Loss: 0.260542\n",
      "Step 125: Generator Loss: 0.258736\n",
      "Step 126: Generator Loss: 0.258444\n",
      "Step 127: Generator Loss: 0.260014\n",
      "Step 128: Generator Loss: 0.259938\n",
      "Step 129: Generator Loss: 0.259712\n",
      "Step 130: Generator Loss: 0.259792\n",
      "Step 131: Generator Loss: 0.260990\n",
      "Step 132: Generator Loss: 0.258898\n",
      "Step 133: Generator Loss: 0.257970\n",
      "Step 134: Generator Loss: 0.257689\n",
      "Step 135: Generator Loss: 0.258633\n",
      "Step 136: Generator Loss: 0.260015\n",
      "Step 137: Generator Loss: 0.256666\n",
      "Step 138: Generator Loss: 0.258416\n",
      "Step 139: Generator Loss: 0.257972\n",
      "Step 140: Generator Loss: 0.256379\n",
      "Step 141: Generator Loss: 0.256883\n",
      "Step 142: Generator Loss: 0.258664\n",
      "Step 143: Generator Loss: 0.255732\n",
      "Step 144: Generator Loss: 0.258522\n",
      "Step 145: Generator Loss: 0.257018\n",
      "Step 146: Generator Loss: 0.258003\n",
      "Step 147: Generator Loss: 0.259415\n",
      "Step 148: Generator Loss: 0.256931\n",
      "Step 149: Generator Loss: 0.255299\n",
      "Step 150: Generator Loss: 0.256609\n",
      "Step 151: Generator Loss: 0.258592\n",
      "Step 152: Generator Loss: 0.255627\n",
      "Step 153: Generator Loss: 0.255284\n",
      "Step 154: Generator Loss: 0.253535\n",
      "Step 155: Generator Loss: 0.254299\n",
      "Step 156: Generator Loss: 0.254881\n",
      "Step 157: Generator Loss: 0.254563\n",
      "Step 158: Generator Loss: 0.254660\n",
      "Step 159: Generator Loss: 0.255178\n",
      "Step 160: Generator Loss: 0.256830\n",
      "Step 161: Generator Loss: 0.253567\n",
      "Step 162: Generator Loss: 0.255069\n",
      "Step 163: Generator Loss: 0.253960\n",
      "Step 164: Generator Loss: 0.255917\n",
      "Step 165: Generator Loss: 0.252791\n",
      "Step 166: Generator Loss: 0.254165\n",
      "Step 167: Generator Loss: 0.253294\n",
      "Step 168: Generator Loss: 0.251774\n",
      "Step 169: Generator Loss: 0.254086\n",
      "Step 170: Generator Loss: 0.251053\n",
      "Step 171: Generator Loss: 0.253335\n",
      "Step 172: Generator Loss: 0.252410\n",
      "Step 173: Generator Loss: 0.252102\n",
      "Step 174: Generator Loss: 0.253140\n",
      "Step 175: Generator Loss: 0.251481\n",
      "Step 176: Generator Loss: 0.252427\n",
      "Step 177: Generator Loss: 0.250569\n",
      "Step 178: Generator Loss: 0.251717\n",
      "Step 179: Generator Loss: 0.251667\n",
      "Step 180: Generator Loss: 0.250487\n",
      "Step 181: Generator Loss: 0.249291\n",
      "Step 182: Generator Loss: 0.250320\n",
      "Step 183: Generator Loss: 0.250526\n",
      "Step 184: Generator Loss: 0.250983\n",
      "Step 185: Generator Loss: 0.252579\n",
      "Step 186: Generator Loss: 0.247252\n",
      "Step 187: Generator Loss: 0.248602\n",
      "Step 188: Generator Loss: 0.249719\n",
      "Step 189: Generator Loss: 0.247796\n",
      "Step 190: Generator Loss: 0.250936\n",
      "Step 191: Generator Loss: 0.249888\n",
      "Step 192: Generator Loss: 0.248078\n",
      "Step 193: Generator Loss: 0.249201\n",
      "Step 194: Generator Loss: 0.249068\n",
      "Step 195: Generator Loss: 0.249021\n",
      "Step 196: Generator Loss: 0.248719\n",
      "Step 197: Generator Loss: 0.246836\n",
      "Step 198: Generator Loss: 0.248220\n",
      "Step 199: Generator Loss: 0.247674\n",
      "Step 200: Generator Loss: 0.247564\n",
      "Step 201: Generator Loss: 0.248581\n",
      "Step 202: Generator Loss: 0.248318\n",
      "Step 203: Generator Loss: 0.246353\n",
      "Step 204: Generator Loss: 0.246530\n",
      "Step 205: Generator Loss: 0.247256\n",
      "Step 206: Generator Loss: 0.247369\n",
      "Step 207: Generator Loss: 0.246262\n",
      "Step 208: Generator Loss: 0.247155\n",
      "Step 209: Generator Loss: 0.246418\n",
      "Step 210: Generator Loss: 0.247243\n",
      "Step 211: Generator Loss: 0.245977\n",
      "Step 212: Generator Loss: 0.246144\n",
      "Step 213: Generator Loss: 0.245360\n",
      "Step 214: Generator Loss: 0.244208\n",
      "Step 215: Generator Loss: 0.245700\n",
      "Step 216: Generator Loss: 0.244486\n",
      "Step 217: Generator Loss: 0.245194\n",
      "Step 218: Generator Loss: 0.244993\n",
      "Step 219: Generator Loss: 0.244278\n",
      "Step 220: Generator Loss: 0.245425\n",
      "Step 221: Generator Loss: 0.244462\n",
      "Step 222: Generator Loss: 0.245442\n",
      "Step 223: Generator Loss: 0.244477\n",
      "Step 224: Generator Loss: 0.243463\n",
      "Step 225: Generator Loss: 0.243315\n",
      "Step 226: Generator Loss: 0.243815\n",
      "Step 227: Generator Loss: 0.244374\n",
      "Step 228: Generator Loss: 0.243950\n",
      "Step 229: Generator Loss: 0.243489\n",
      "Step 230: Generator Loss: 0.242196\n",
      "Step 231: Generator Loss: 0.244219\n",
      "Step 232: Generator Loss: 0.243403\n",
      "Step 233: Generator Loss: 0.243520\n",
      "Step 234: Generator Loss: 0.244251\n",
      "Step 235: Generator Loss: 0.242887\n",
      "Step 236: Generator Loss: 0.241763\n",
      "Step 237: Generator Loss: 0.242563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 238: Generator Loss: 0.242442\n",
      "Step 239: Generator Loss: 0.242606\n",
      "Step 240: Generator Loss: 0.242597\n",
      "Step 241: Generator Loss: 0.241100\n",
      "Step 242: Generator Loss: 0.241418\n",
      "Step 243: Generator Loss: 0.241706\n",
      "Step 244: Generator Loss: 0.241767\n",
      "Step 245: Generator Loss: 0.240793\n",
      "Step 246: Generator Loss: 0.240348\n",
      "Step 247: Generator Loss: 0.239176\n",
      "Step 248: Generator Loss: 0.240634\n",
      "Step 249: Generator Loss: 0.240717\n",
      "Step 250: Generator Loss: 0.240145\n",
      "Step 251: Generator Loss: 0.242668\n",
      "Step 252: Generator Loss: 0.240081\n",
      "Step 253: Generator Loss: 0.238880\n",
      "Step 254: Generator Loss: 0.240689\n",
      "Step 255: Generator Loss: 0.239240\n",
      "Step 256: Generator Loss: 0.239473\n",
      "Step 257: Generator Loss: 0.240209\n",
      "Step 258: Generator Loss: 0.239293\n",
      "Step 259: Generator Loss: 0.239114\n",
      "Step 260: Generator Loss: 0.240237\n",
      "Step 261: Generator Loss: 0.239324\n",
      "Step 262: Generator Loss: 0.238740\n",
      "Step 263: Generator Loss: 0.241301\n",
      "Step 264: Generator Loss: 0.238450\n",
      "Step 265: Generator Loss: 0.238225\n",
      "Step 266: Generator Loss: 0.237786\n",
      "Step 267: Generator Loss: 0.239954\n",
      "Step 268: Generator Loss: 0.237014\n",
      "Step 269: Generator Loss: 0.238045\n",
      "Step 270: Generator Loss: 0.236131\n",
      "Step 271: Generator Loss: 0.236928\n",
      "Step 272: Generator Loss: 0.236051\n",
      "Step 273: Generator Loss: 0.237547\n",
      "Step 274: Generator Loss: 0.236478\n",
      "Step 275: Generator Loss: 0.236419\n",
      "Step 276: Generator Loss: 0.238134\n",
      "Step 277: Generator Loss: 0.235772\n",
      "Step 278: Generator Loss: 0.236325\n",
      "Step 279: Generator Loss: 0.235874\n",
      "Step 280: Generator Loss: 0.235301\n",
      "Step 281: Generator Loss: 0.235848\n",
      "Step 282: Generator Loss: 0.236137\n",
      "Step 283: Generator Loss: 0.234405\n",
      "Step 284: Generator Loss: 0.235807\n",
      "Step 285: Generator Loss: 0.236473\n",
      "Step 286: Generator Loss: 0.234165\n",
      "Step 287: Generator Loss: 0.234687\n",
      "Step 288: Generator Loss: 0.234294\n",
      "Step 289: Generator Loss: 0.235221\n",
      "Step 290: Generator Loss: 0.234664\n",
      "Step 291: Generator Loss: 0.234436\n",
      "Step 292: Generator Loss: 0.234525\n",
      "Step 293: Generator Loss: 0.234821\n",
      "Step 294: Generator Loss: 0.235639\n",
      "Step 295: Generator Loss: 0.234100\n",
      "Step 296: Generator Loss: 0.233833\n",
      "Step 297: Generator Loss: 0.233036\n",
      "Step 298: Generator Loss: 0.232782\n",
      "Step 299: Generator Loss: 0.235367\n",
      "Step 300: Generator Loss: 0.231244\n",
      "Step 301: Generator Loss: 0.232463\n",
      "Step 302: Generator Loss: 0.234065\n",
      "Step 303: Generator Loss: 0.233953\n",
      "Step 304: Generator Loss: 0.232102\n",
      "Step 305: Generator Loss: 0.232218\n",
      "Step 306: Generator Loss: 0.232256\n",
      "Step 307: Generator Loss: 0.233331\n",
      "Step 308: Generator Loss: 0.232718\n",
      "Step 309: Generator Loss: 0.231622\n",
      "Step 310: Generator Loss: 0.230729\n",
      "Step 311: Generator Loss: 0.230087\n",
      "Step 312: Generator Loss: 0.231927\n",
      "Step 313: Generator Loss: 0.230764\n",
      "Step 314: Generator Loss: 0.230436\n",
      "Step 315: Generator Loss: 0.233393\n",
      "Step 316: Generator Loss: 0.229668\n",
      "Step 317: Generator Loss: 0.230361\n",
      "Step 318: Generator Loss: 0.232165\n",
      "Step 319: Generator Loss: 0.230016\n",
      "Step 320: Generator Loss: 0.229710\n",
      "Step 321: Generator Loss: 0.229577\n",
      "Step 322: Generator Loss: 0.228894\n",
      "Step 323: Generator Loss: 0.229652\n",
      "Step 324: Generator Loss: 0.228690\n",
      "Step 325: Generator Loss: 0.228778\n",
      "Step 326: Generator Loss: 0.229672\n",
      "Step 327: Generator Loss: 0.229549\n",
      "Step 328: Generator Loss: 0.228070\n",
      "Step 329: Generator Loss: 0.228225\n",
      "Step 330: Generator Loss: 0.228535\n",
      "Step 331: Generator Loss: 0.228051\n",
      "Step 332: Generator Loss: 0.229043\n",
      "Step 333: Generator Loss: 0.228665\n",
      "Step 334: Generator Loss: 0.226766\n",
      "Step 335: Generator Loss: 0.227643\n",
      "Step 336: Generator Loss: 0.228082\n",
      "Step 337: Generator Loss: 0.228127\n",
      "Step 338: Generator Loss: 0.227164\n",
      "Step 339: Generator Loss: 0.226095\n",
      "Step 340: Generator Loss: 0.226576\n",
      "Step 341: Generator Loss: 0.226054\n",
      "Step 342: Generator Loss: 0.227063\n",
      "Step 343: Generator Loss: 0.226085\n",
      "Step 344: Generator Loss: 0.226846\n",
      "Step 345: Generator Loss: 0.227991\n",
      "Step 346: Generator Loss: 0.227791\n",
      "Step 347: Generator Loss: 0.225981\n",
      "Step 348: Generator Loss: 0.227133\n",
      "Step 349: Generator Loss: 0.225587\n",
      "Step 350: Generator Loss: 0.226227\n",
      "Step 351: Generator Loss: 0.224419\n",
      "Step 352: Generator Loss: 0.227480\n",
      "Step 353: Generator Loss: 0.224656\n",
      "Step 354: Generator Loss: 0.225507\n",
      "Step 355: Generator Loss: 0.225619\n",
      "Step 356: Generator Loss: 0.225728\n",
      "Step 357: Generator Loss: 0.225161\n",
      "Step 358: Generator Loss: 0.225188\n",
      "Step 359: Generator Loss: 0.224082\n",
      "Step 360: Generator Loss: 0.224891\n",
      "Step 361: Generator Loss: 0.223839\n",
      "Step 362: Generator Loss: 0.223855\n",
      "Step 363: Generator Loss: 0.223743\n",
      "Step 364: Generator Loss: 0.225357\n",
      "Step 365: Generator Loss: 0.222798\n",
      "Step 366: Generator Loss: 0.222652\n",
      "Step 367: Generator Loss: 0.223669\n",
      "Step 368: Generator Loss: 0.222894\n",
      "Step 369: Generator Loss: 0.222443\n",
      "Step 370: Generator Loss: 0.225270\n",
      "Step 371: Generator Loss: 0.223178\n",
      "Step 372: Generator Loss: 0.221859\n",
      "Step 373: Generator Loss: 0.224369\n",
      "Step 374: Generator Loss: 0.222311\n",
      "Step 375: Generator Loss: 0.223367\n",
      "Step 376: Generator Loss: 0.222533\n",
      "Step 377: Generator Loss: 0.223275\n",
      "Step 378: Generator Loss: 0.220806\n",
      "Step 379: Generator Loss: 0.223370\n",
      "Step 380: Generator Loss: 0.223300\n",
      "Step 381: Generator Loss: 0.219523\n",
      "Step 382: Generator Loss: 0.220493\n",
      "Step 383: Generator Loss: 0.219970\n",
      "Step 384: Generator Loss: 0.220684\n",
      "Step 385: Generator Loss: 0.221976\n",
      "Step 386: Generator Loss: 0.220314\n",
      "Step 387: Generator Loss: 0.219698\n",
      "Step 388: Generator Loss: 0.221054\n",
      "Step 389: Generator Loss: 0.219726\n",
      "Step 390: Generator Loss: 0.221966\n",
      "Step 391: Generator Loss: 0.219015\n",
      "Step 392: Generator Loss: 0.219818\n",
      "Step 393: Generator Loss: 0.220714\n",
      "Step 394: Generator Loss: 0.218082\n",
      "Step 395: Generator Loss: 0.219755\n",
      "Step 396: Generator Loss: 0.219272\n",
      "Step 397: Generator Loss: 0.220297\n",
      "Step 398: Generator Loss: 0.217619\n",
      "Step 399: Generator Loss: 0.218942\n",
      "Step 400: Generator Loss: 0.218745\n",
      "Step 401: Generator Loss: 0.219067\n",
      "Step 402: Generator Loss: 0.219547\n",
      "Step 403: Generator Loss: 0.217111\n",
      "Step 404: Generator Loss: 0.218398\n",
      "Step 405: Generator Loss: 0.218665\n",
      "Step 406: Generator Loss: 0.217281\n",
      "Step 407: Generator Loss: 0.218255\n",
      "Step 408: Generator Loss: 0.217319\n",
      "Step 409: Generator Loss: 0.216153\n",
      "Step 410: Generator Loss: 0.216540\n",
      "Step 411: Generator Loss: 0.215239\n",
      "Step 412: Generator Loss: 0.218979\n",
      "Step 413: Generator Loss: 0.216855\n",
      "Step 414: Generator Loss: 0.217042\n",
      "Step 415: Generator Loss: 0.217712\n",
      "Step 416: Generator Loss: 0.216666\n",
      "Step 417: Generator Loss: 0.218585\n",
      "Step 418: Generator Loss: 0.215878\n",
      "Step 419: Generator Loss: 0.215493\n",
      "Step 420: Generator Loss: 0.214944\n",
      "Step 421: Generator Loss: 0.216103\n",
      "Step 422: Generator Loss: 0.216421\n",
      "Step 423: Generator Loss: 0.214631\n",
      "Step 424: Generator Loss: 0.215362\n",
      "Step 425: Generator Loss: 0.214832\n",
      "Step 426: Generator Loss: 0.214929\n",
      "Step 427: Generator Loss: 0.215401\n",
      "Step 428: Generator Loss: 0.215054\n",
      "Step 429: Generator Loss: 0.214505\n",
      "Step 430: Generator Loss: 0.215777\n",
      "Step 431: Generator Loss: 0.214242\n",
      "Step 432: Generator Loss: 0.213683\n",
      "Step 433: Generator Loss: 0.215534\n",
      "Step 434: Generator Loss: 0.214479\n",
      "Step 435: Generator Loss: 0.213131\n",
      "Step 436: Generator Loss: 0.214422\n",
      "Step 437: Generator Loss: 0.214526\n",
      "Step 438: Generator Loss: 0.215061\n",
      "Step 439: Generator Loss: 0.212341\n",
      "Step 440: Generator Loss: 0.213871\n",
      "Step 441: Generator Loss: 0.211976\n",
      "Step 442: Generator Loss: 0.213002\n",
      "Step 443: Generator Loss: 0.212378\n",
      "Step 444: Generator Loss: 0.212031\n",
      "Step 445: Generator Loss: 0.212504\n",
      "Step 446: Generator Loss: 0.213447\n",
      "Step 447: Generator Loss: 0.212900\n",
      "Step 448: Generator Loss: 0.211639\n",
      "Step 449: Generator Loss: 0.211316\n",
      "Step 450: Generator Loss: 0.212040\n",
      "Step 451: Generator Loss: 0.211851\n",
      "Step 452: Generator Loss: 0.212324\n",
      "Step 453: Generator Loss: 0.210952\n",
      "Step 454: Generator Loss: 0.211633\n",
      "Step 455: Generator Loss: 0.209247\n",
      "Step 456: Generator Loss: 0.210875\n",
      "Step 457: Generator Loss: 0.210357\n",
      "Step 458: Generator Loss: 0.209947\n",
      "Step 459: Generator Loss: 0.209708\n",
      "Step 460: Generator Loss: 0.210768\n",
      "Step 461: Generator Loss: 0.209397\n",
      "Step 462: Generator Loss: 0.207794\n",
      "Step 463: Generator Loss: 0.208520\n",
      "Step 464: Generator Loss: 0.210056\n",
      "Step 465: Generator Loss: 0.207992\n",
      "Step 466: Generator Loss: 0.209230\n",
      "Step 467: Generator Loss: 0.210628\n",
      "Step 468: Generator Loss: 0.210133\n",
      "Step 469: Generator Loss: 0.210734\n",
      "Step 470: Generator Loss: 0.209763\n",
      "Step 471: Generator Loss: 0.208672\n",
      "Step 472: Generator Loss: 0.208369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 473: Generator Loss: 0.207870\n",
      "Step 474: Generator Loss: 0.207713\n",
      "Step 475: Generator Loss: 0.208481\n",
      "Step 476: Generator Loss: 0.208279\n",
      "Step 477: Generator Loss: 0.207608\n",
      "Step 478: Generator Loss: 0.207820\n",
      "Step 479: Generator Loss: 0.207127\n",
      "Step 480: Generator Loss: 0.207389\n",
      "Step 481: Generator Loss: 0.207869\n",
      "Step 482: Generator Loss: 0.207069\n",
      "Step 483: Generator Loss: 0.207056\n",
      "Step 484: Generator Loss: 0.207222\n",
      "Step 485: Generator Loss: 0.207881\n",
      "Step 486: Generator Loss: 0.204656\n",
      "Step 487: Generator Loss: 0.207301\n",
      "Step 488: Generator Loss: 0.207172\n",
      "Step 489: Generator Loss: 0.206176\n",
      "Step 490: Generator Loss: 0.206938\n",
      "Step 491: Generator Loss: 0.205260\n",
      "Step 492: Generator Loss: 0.207981\n",
      "Step 493: Generator Loss: 0.203722\n",
      "Step 494: Generator Loss: 0.205728\n",
      "Step 495: Generator Loss: 0.206081\n",
      "Step 496: Generator Loss: 0.205160\n",
      "Step 497: Generator Loss: 0.206971\n",
      "Step 498: Generator Loss: 0.205942\n",
      "Step 499: Generator Loss: 0.205516\n",
      "Step 500: Generator Loss: 0.204130\n",
      "Step 501: Generator Loss: 0.205925\n",
      "Step 502: Generator Loss: 0.202910\n",
      "Step 503: Generator Loss: 0.203940\n",
      "Step 504: Generator Loss: 0.204567\n",
      "Step 505: Generator Loss: 0.203217\n",
      "Step 506: Generator Loss: 0.203648\n",
      "Step 507: Generator Loss: 0.202072\n",
      "Step 508: Generator Loss: 0.204541\n",
      "Step 509: Generator Loss: 0.203057\n",
      "Step 510: Generator Loss: 0.204213\n",
      "Step 511: Generator Loss: 0.204484\n",
      "Step 512: Generator Loss: 0.202069\n",
      "Step 513: Generator Loss: 0.203708\n",
      "Step 514: Generator Loss: 0.201220\n",
      "Step 515: Generator Loss: 0.202178\n",
      "Step 516: Generator Loss: 0.201715\n",
      "Step 517: Generator Loss: 0.200321\n",
      "Step 518: Generator Loss: 0.201422\n",
      "Step 519: Generator Loss: 0.202197\n",
      "Step 520: Generator Loss: 0.202512\n",
      "Step 521: Generator Loss: 0.201884\n",
      "Step 522: Generator Loss: 0.199606\n",
      "Step 523: Generator Loss: 0.200796\n",
      "Step 524: Generator Loss: 0.200647\n",
      "Step 525: Generator Loss: 0.201128\n",
      "Step 526: Generator Loss: 0.200669\n",
      "Step 527: Generator Loss: 0.200250\n",
      "Step 528: Generator Loss: 0.200531\n",
      "Step 529: Generator Loss: 0.202229\n",
      "Step 530: Generator Loss: 0.200970\n",
      "Step 531: Generator Loss: 0.198512\n",
      "Step 532: Generator Loss: 0.199494\n",
      "Step 533: Generator Loss: 0.199789\n",
      "Step 534: Generator Loss: 0.199430\n",
      "Step 535: Generator Loss: 0.199378\n",
      "Step 536: Generator Loss: 0.198546\n",
      "Step 537: Generator Loss: 0.199898\n",
      "Step 538: Generator Loss: 0.198606\n",
      "Step 539: Generator Loss: 0.198134\n",
      "Step 540: Generator Loss: 0.199151\n",
      "Step 541: Generator Loss: 0.197881\n",
      "Step 542: Generator Loss: 0.198622\n",
      "Step 543: Generator Loss: 0.198769\n",
      "Step 544: Generator Loss: 0.199069\n",
      "Step 545: Generator Loss: 0.199149\n",
      "Step 546: Generator Loss: 0.200326\n",
      "Step 547: Generator Loss: 0.197414\n",
      "Step 548: Generator Loss: 0.196649\n",
      "Step 549: Generator Loss: 0.198016\n",
      "Step 550: Generator Loss: 0.197168\n",
      "Step 551: Generator Loss: 0.198821\n",
      "Step 552: Generator Loss: 0.195667\n",
      "Step 553: Generator Loss: 0.195480\n",
      "Step 554: Generator Loss: 0.197725\n",
      "Step 555: Generator Loss: 0.197658\n",
      "Step 556: Generator Loss: 0.194372\n",
      "Step 557: Generator Loss: 0.197210\n",
      "Step 558: Generator Loss: 0.196368\n",
      "Step 559: Generator Loss: 0.194000\n",
      "Step 560: Generator Loss: 0.195437\n",
      "Step 561: Generator Loss: 0.194961\n",
      "Step 562: Generator Loss: 0.197062\n",
      "Step 563: Generator Loss: 0.194619\n",
      "Step 564: Generator Loss: 0.197103\n",
      "Step 565: Generator Loss: 0.197448\n",
      "Step 566: Generator Loss: 0.195788\n",
      "Step 567: Generator Loss: 0.194051\n",
      "Step 568: Generator Loss: 0.195444\n",
      "Step 569: Generator Loss: 0.193741\n",
      "Step 570: Generator Loss: 0.195310\n",
      "Step 571: Generator Loss: 0.195419\n",
      "Step 572: Generator Loss: 0.197230\n",
      "Step 573: Generator Loss: 0.197282\n",
      "Step 574: Generator Loss: 0.193412\n",
      "Step 575: Generator Loss: 0.193014\n",
      "Step 576: Generator Loss: 0.191585\n",
      "Step 577: Generator Loss: 0.193199\n",
      "Step 578: Generator Loss: 0.192049\n",
      "Step 579: Generator Loss: 0.193735\n",
      "Step 580: Generator Loss: 0.194793\n",
      "Step 581: Generator Loss: 0.193724\n",
      "Step 582: Generator Loss: 0.191946\n",
      "Step 583: Generator Loss: 0.193560\n",
      "Step 584: Generator Loss: 0.189634\n",
      "Step 585: Generator Loss: 0.191251\n",
      "Step 586: Generator Loss: 0.188004\n",
      "Step 587: Generator Loss: 0.190122\n",
      "Step 588: Generator Loss: 0.189844\n",
      "Step 589: Generator Loss: 0.191726\n",
      "Step 590: Generator Loss: 0.191735\n",
      "Step 591: Generator Loss: 0.190721\n",
      "Step 592: Generator Loss: 0.192833\n",
      "Step 593: Generator Loss: 0.188664\n",
      "Step 594: Generator Loss: 0.191128\n",
      "Step 595: Generator Loss: 0.190096\n",
      "Step 596: Generator Loss: 0.190929\n",
      "Step 597: Generator Loss: 0.190411\n",
      "Step 598: Generator Loss: 0.190300\n",
      "Step 599: Generator Loss: 0.189528\n",
      "Step 600: Generator Loss: 0.189178\n",
      "Step 601: Generator Loss: 0.190556\n",
      "Step 602: Generator Loss: 0.189752\n",
      "Step 603: Generator Loss: 0.189215\n",
      "Step 604: Generator Loss: 0.190138\n",
      "Step 605: Generator Loss: 0.189990\n",
      "Step 606: Generator Loss: 0.188355\n",
      "Step 607: Generator Loss: 0.185366\n",
      "Step 608: Generator Loss: 0.188623\n",
      "Step 609: Generator Loss: 0.189110\n",
      "Step 610: Generator Loss: 0.187851\n",
      "Step 611: Generator Loss: 0.187186\n",
      "Step 612: Generator Loss: 0.188188\n",
      "Step 613: Generator Loss: 0.186837\n",
      "Step 614: Generator Loss: 0.186483\n",
      "Step 615: Generator Loss: 0.187553\n",
      "Step 616: Generator Loss: 0.187772\n",
      "Step 617: Generator Loss: 0.187745\n",
      "Step 618: Generator Loss: 0.186950\n",
      "Step 619: Generator Loss: 0.186744\n",
      "Step 620: Generator Loss: 0.187041\n",
      "Step 621: Generator Loss: 0.188931\n",
      "Step 622: Generator Loss: 0.185360\n",
      "Step 623: Generator Loss: 0.186265\n",
      "Step 624: Generator Loss: 0.187181\n",
      "Step 625: Generator Loss: 0.188048\n",
      "Step 626: Generator Loss: 0.185146\n",
      "Step 627: Generator Loss: 0.183729\n",
      "Step 628: Generator Loss: 0.184480\n",
      "Step 629: Generator Loss: 0.185185\n",
      "Step 630: Generator Loss: 0.183819\n",
      "Step 631: Generator Loss: 0.182398\n",
      "Step 632: Generator Loss: 0.185672\n",
      "Step 633: Generator Loss: 0.187722\n",
      "Step 634: Generator Loss: 0.185402\n",
      "Step 635: Generator Loss: 0.185063\n",
      "Step 636: Generator Loss: 0.183217\n",
      "Step 637: Generator Loss: 0.181118\n",
      "Step 638: Generator Loss: 0.184205\n",
      "Step 639: Generator Loss: 0.183402\n",
      "Step 640: Generator Loss: 0.184916\n",
      "Step 641: Generator Loss: 0.183419\n",
      "Step 642: Generator Loss: 0.182609\n",
      "Step 643: Generator Loss: 0.181078\n",
      "Step 644: Generator Loss: 0.184975\n",
      "Step 645: Generator Loss: 0.180284\n",
      "Step 646: Generator Loss: 0.183555\n",
      "Step 647: Generator Loss: 0.180078\n",
      "Step 648: Generator Loss: 0.183532\n",
      "Step 649: Generator Loss: 0.181100\n",
      "Step 650: Generator Loss: 0.179929\n",
      "Step 651: Generator Loss: 0.179449\n",
      "Step 652: Generator Loss: 0.181308\n",
      "Step 653: Generator Loss: 0.182078\n",
      "Step 654: Generator Loss: 0.179579\n",
      "Step 655: Generator Loss: 0.181530\n",
      "Step 656: Generator Loss: 0.180263\n",
      "Step 657: Generator Loss: 0.182182\n",
      "Step 658: Generator Loss: 0.179180\n",
      "Step 659: Generator Loss: 0.182370\n",
      "Step 660: Generator Loss: 0.180506\n",
      "Step 661: Generator Loss: 0.178914\n",
      "Step 662: Generator Loss: 0.182110\n",
      "Step 663: Generator Loss: 0.178972\n",
      "Step 664: Generator Loss: 0.179249\n",
      "Step 665: Generator Loss: 0.179782\n",
      "Step 666: Generator Loss: 0.179616\n",
      "Step 667: Generator Loss: 0.177911\n",
      "Step 668: Generator Loss: 0.176261\n",
      "Step 669: Generator Loss: 0.178838\n",
      "Step 670: Generator Loss: 0.179282\n",
      "Step 671: Generator Loss: 0.178621\n",
      "Step 672: Generator Loss: 0.178176\n",
      "Step 673: Generator Loss: 0.179367\n",
      "Step 674: Generator Loss: 0.176543\n",
      "Step 675: Generator Loss: 0.178617\n",
      "Step 676: Generator Loss: 0.177332\n",
      "Step 677: Generator Loss: 0.178706\n",
      "Step 678: Generator Loss: 0.175814\n",
      "Step 679: Generator Loss: 0.178107\n",
      "Step 680: Generator Loss: 0.173607\n",
      "Step 681: Generator Loss: 0.175646\n",
      "Step 682: Generator Loss: 0.177171\n",
      "Step 683: Generator Loss: 0.179153\n",
      "Step 684: Generator Loss: 0.175510\n",
      "Step 685: Generator Loss: 0.176872\n",
      "Step 686: Generator Loss: 0.175875\n",
      "Step 687: Generator Loss: 0.177084\n",
      "Step 688: Generator Loss: 0.178120\n",
      "Step 689: Generator Loss: 0.177147\n",
      "Step 690: Generator Loss: 0.178684\n",
      "Step 691: Generator Loss: 0.175354\n",
      "Step 692: Generator Loss: 0.174926\n",
      "Step 693: Generator Loss: 0.174860\n",
      "Step 694: Generator Loss: 0.174350\n",
      "Step 695: Generator Loss: 0.175363\n",
      "Step 696: Generator Loss: 0.176076\n",
      "Step 697: Generator Loss: 0.172922\n",
      "Step 698: Generator Loss: 0.176096\n",
      "Step 699: Generator Loss: 0.174262\n",
      "Step 700: Generator Loss: 0.174100\n",
      "Step 701: Generator Loss: 0.173220\n",
      "Step 702: Generator Loss: 0.173722\n",
      "Step 703: Generator Loss: 0.172250\n",
      "Step 704: Generator Loss: 0.172296\n",
      "Step 705: Generator Loss: 0.173194\n",
      "Step 706: Generator Loss: 0.173791\n",
      "Step 707: Generator Loss: 0.173794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 708: Generator Loss: 0.169049\n",
      "Step 709: Generator Loss: 0.172737\n",
      "Step 710: Generator Loss: 0.172504\n",
      "Step 711: Generator Loss: 0.172961\n",
      "Step 712: Generator Loss: 0.171428\n",
      "Step 713: Generator Loss: 0.169616\n",
      "Step 714: Generator Loss: 0.173018\n",
      "Step 715: Generator Loss: 0.174008\n",
      "Step 716: Generator Loss: 0.171600\n",
      "Step 717: Generator Loss: 0.168977\n",
      "Step 718: Generator Loss: 0.169319\n",
      "Step 719: Generator Loss: 0.170400\n",
      "Step 720: Generator Loss: 0.170590\n",
      "Step 721: Generator Loss: 0.170426\n",
      "Step 722: Generator Loss: 0.174038\n",
      "Step 723: Generator Loss: 0.171086\n",
      "Step 724: Generator Loss: 0.173796\n",
      "Step 725: Generator Loss: 0.169265\n",
      "Step 726: Generator Loss: 0.168704\n",
      "Step 727: Generator Loss: 0.168145\n",
      "Step 728: Generator Loss: 0.168954\n",
      "Step 729: Generator Loss: 0.175170\n",
      "Step 730: Generator Loss: 0.169343\n",
      "Step 731: Generator Loss: 0.168247\n",
      "Step 732: Generator Loss: 0.168499\n",
      "Step 733: Generator Loss: 0.170410\n",
      "Step 734: Generator Loss: 0.167339\n",
      "Step 735: Generator Loss: 0.170187\n",
      "Step 736: Generator Loss: 0.169225\n",
      "Step 737: Generator Loss: 0.166247\n",
      "Step 738: Generator Loss: 0.164180\n",
      "Step 739: Generator Loss: 0.165292\n",
      "Step 740: Generator Loss: 0.170148\n",
      "Step 741: Generator Loss: 0.167517\n",
      "Step 742: Generator Loss: 0.169504\n",
      "Step 743: Generator Loss: 0.167717\n",
      "Step 744: Generator Loss: 0.168329\n",
      "Step 745: Generator Loss: 0.168149\n",
      "Step 746: Generator Loss: 0.164150\n",
      "Step 747: Generator Loss: 0.162521\n",
      "Step 748: Generator Loss: 0.164281\n",
      "Step 749: Generator Loss: 0.168497\n",
      "Step 750: Generator Loss: 0.166927\n",
      "Step 751: Generator Loss: 0.163339\n",
      "Step 752: Generator Loss: 0.168014\n",
      "Step 753: Generator Loss: 0.167066\n",
      "Step 754: Generator Loss: 0.164495\n",
      "Step 755: Generator Loss: 0.167343\n",
      "Step 756: Generator Loss: 0.165553\n",
      "Step 757: Generator Loss: 0.164047\n",
      "Step 758: Generator Loss: 0.163253\n",
      "Step 759: Generator Loss: 0.164935\n",
      "Step 760: Generator Loss: 0.163083\n",
      "Step 761: Generator Loss: 0.166838\n",
      "Step 762: Generator Loss: 0.164658\n",
      "Step 763: Generator Loss: 0.162791\n",
      "Step 764: Generator Loss: 0.166011\n",
      "Step 765: Generator Loss: 0.162241\n",
      "Step 766: Generator Loss: 0.162973\n",
      "Step 767: Generator Loss: 0.159873\n",
      "Step 768: Generator Loss: 0.159987\n",
      "Step 769: Generator Loss: 0.159311\n",
      "Step 770: Generator Loss: 0.164957\n",
      "Step 771: Generator Loss: 0.161772\n",
      "Step 772: Generator Loss: 0.162349\n",
      "Step 773: Generator Loss: 0.164432\n",
      "Step 774: Generator Loss: 0.163437\n",
      "Step 775: Generator Loss: 0.162327\n",
      "Step 776: Generator Loss: 0.158159\n",
      "Step 777: Generator Loss: 0.162803\n",
      "Step 778: Generator Loss: 0.163839\n",
      "Step 779: Generator Loss: 0.163838\n",
      "Step 780: Generator Loss: 0.161081\n",
      "Step 781: Generator Loss: 0.162809\n",
      "Step 782: Generator Loss: 0.157669\n",
      "Step 783: Generator Loss: 0.161709\n",
      "Step 784: Generator Loss: 0.161537\n",
      "Step 785: Generator Loss: 0.161833\n",
      "Step 786: Generator Loss: 0.157432\n",
      "Step 787: Generator Loss: 0.158697\n",
      "Step 788: Generator Loss: 0.157110\n",
      "Step 789: Generator Loss: 0.161004\n",
      "Step 790: Generator Loss: 0.158310\n",
      "Step 791: Generator Loss: 0.156350\n",
      "Step 792: Generator Loss: 0.160310\n",
      "Step 793: Generator Loss: 0.160893\n",
      "Step 794: Generator Loss: 0.158928\n",
      "Step 795: Generator Loss: 0.158351\n",
      "Step 796: Generator Loss: 0.157825\n",
      "Step 797: Generator Loss: 0.153884\n",
      "Step 798: Generator Loss: 0.158879\n",
      "Step 799: Generator Loss: 0.155525\n",
      "Step 800: Generator Loss: 0.155583\n",
      "Step 801: Generator Loss: 0.159470\n",
      "Step 802: Generator Loss: 0.159095\n",
      "Step 803: Generator Loss: 0.159428\n",
      "Step 804: Generator Loss: 0.157393\n",
      "Step 805: Generator Loss: 0.159223\n",
      "Step 806: Generator Loss: 0.157434\n",
      "Step 807: Generator Loss: 0.155668\n",
      "Step 808: Generator Loss: 0.158267\n",
      "Step 809: Generator Loss: 0.152473\n",
      "Step 810: Generator Loss: 0.154714\n",
      "Step 811: Generator Loss: 0.156398\n",
      "Step 812: Generator Loss: 0.156360\n",
      "Step 813: Generator Loss: 0.155925\n",
      "Step 814: Generator Loss: 0.155568\n",
      "Step 815: Generator Loss: 0.155377\n",
      "Step 816: Generator Loss: 0.157164\n",
      "Step 817: Generator Loss: 0.158748\n",
      "Step 818: Generator Loss: 0.156458\n",
      "Step 819: Generator Loss: 0.154653\n",
      "Step 820: Generator Loss: 0.156216\n",
      "Step 821: Generator Loss: 0.155411\n",
      "Step 822: Generator Loss: 0.153545\n",
      "Step 823: Generator Loss: 0.156179\n",
      "Step 824: Generator Loss: 0.154029\n",
      "Step 825: Generator Loss: 0.152013\n",
      "Step 826: Generator Loss: 0.154622\n",
      "Step 827: Generator Loss: 0.155905\n",
      "Step 828: Generator Loss: 0.155553\n",
      "Step 829: Generator Loss: 0.154423\n",
      "Step 830: Generator Loss: 0.151550\n",
      "Step 831: Generator Loss: 0.152957\n",
      "Step 832: Generator Loss: 0.157036\n",
      "Step 833: Generator Loss: 0.155773\n",
      "Step 834: Generator Loss: 0.149904\n",
      "Step 835: Generator Loss: 0.155317\n",
      "Step 836: Generator Loss: 0.149513\n",
      "Step 837: Generator Loss: 0.156278\n",
      "Step 838: Generator Loss: 0.156559\n",
      "Step 839: Generator Loss: 0.151141\n",
      "Step 840: Generator Loss: 0.152027\n",
      "Step 841: Generator Loss: 0.152222\n",
      "Step 842: Generator Loss: 0.152636\n",
      "Step 843: Generator Loss: 0.155722\n",
      "Step 844: Generator Loss: 0.152608\n",
      "Step 845: Generator Loss: 0.150810\n",
      "Step 846: Generator Loss: 0.152525\n",
      "Step 847: Generator Loss: 0.153971\n",
      "Step 848: Generator Loss: 0.152566\n",
      "Step 849: Generator Loss: 0.154473\n",
      "Step 850: Generator Loss: 0.151319\n",
      "Step 851: Generator Loss: 0.151228\n",
      "Step 852: Generator Loss: 0.149320\n",
      "Step 853: Generator Loss: 0.150484\n",
      "Step 854: Generator Loss: 0.146432\n",
      "Step 855: Generator Loss: 0.153826\n",
      "Step 856: Generator Loss: 0.149202\n",
      "Step 857: Generator Loss: 0.146058\n",
      "Step 858: Generator Loss: 0.145082\n",
      "Step 859: Generator Loss: 0.156341\n",
      "Step 860: Generator Loss: 0.150932\n",
      "Step 861: Generator Loss: 0.149102\n",
      "Step 862: Generator Loss: 0.148624\n",
      "Step 863: Generator Loss: 0.149827\n",
      "Step 864: Generator Loss: 0.144649\n",
      "Step 865: Generator Loss: 0.143890\n",
      "Step 866: Generator Loss: 0.146216\n",
      "Step 867: Generator Loss: 0.146174\n",
      "Step 868: Generator Loss: 0.147534\n",
      "Step 869: Generator Loss: 0.153299\n",
      "Step 870: Generator Loss: 0.148695\n",
      "Step 871: Generator Loss: 0.146962\n",
      "Step 872: Generator Loss: 0.146608\n",
      "Step 873: Generator Loss: 0.148511\n",
      "Step 874: Generator Loss: 0.144041\n",
      "Step 875: Generator Loss: 0.146402\n",
      "Step 876: Generator Loss: 0.146609\n",
      "Step 877: Generator Loss: 0.145110\n",
      "Step 878: Generator Loss: 0.145115\n",
      "Step 879: Generator Loss: 0.146702\n",
      "Step 880: Generator Loss: 0.149353\n",
      "Step 881: Generator Loss: 0.144120\n",
      "Step 882: Generator Loss: 0.150373\n",
      "Step 883: Generator Loss: 0.147197\n",
      "Step 884: Generator Loss: 0.147289\n",
      "Step 885: Generator Loss: 0.147816\n",
      "Step 886: Generator Loss: 0.141557\n",
      "Step 887: Generator Loss: 0.149850\n",
      "Step 888: Generator Loss: 0.144948\n",
      "Step 889: Generator Loss: 0.142412\n",
      "Step 890: Generator Loss: 0.145737\n",
      "Step 891: Generator Loss: 0.144040\n",
      "Step 892: Generator Loss: 0.144440\n",
      "Step 893: Generator Loss: 0.145572\n",
      "Step 894: Generator Loss: 0.143476\n",
      "Step 895: Generator Loss: 0.143869\n",
      "Step 896: Generator Loss: 0.146476\n",
      "Step 897: Generator Loss: 0.145001\n",
      "Step 898: Generator Loss: 0.142094\n",
      "Step 899: Generator Loss: 0.138286\n",
      "Step 900: Generator Loss: 0.141707\n",
      "Step 901: Generator Loss: 0.143596\n",
      "Step 902: Generator Loss: 0.143063\n",
      "Step 903: Generator Loss: 0.145271\n",
      "Step 904: Generator Loss: 0.143074\n",
      "Step 905: Generator Loss: 0.143151\n",
      "Step 906: Generator Loss: 0.141593\n",
      "Step 907: Generator Loss: 0.139951\n",
      "Step 908: Generator Loss: 0.137915\n",
      "Step 909: Generator Loss: 0.142744\n",
      "Step 910: Generator Loss: 0.145560\n",
      "Step 911: Generator Loss: 0.141843\n",
      "Step 912: Generator Loss: 0.137365\n",
      "Step 913: Generator Loss: 0.139660\n",
      "Step 914: Generator Loss: 0.141109\n",
      "Step 915: Generator Loss: 0.143481\n",
      "Step 916: Generator Loss: 0.140535\n",
      "Step 917: Generator Loss: 0.144881\n",
      "Step 918: Generator Loss: 0.141827\n",
      "Step 919: Generator Loss: 0.138613\n",
      "Step 920: Generator Loss: 0.141766\n",
      "Step 921: Generator Loss: 0.132882\n",
      "Step 922: Generator Loss: 0.144178\n",
      "Step 923: Generator Loss: 0.137865\n",
      "Step 924: Generator Loss: 0.142174\n",
      "Step 925: Generator Loss: 0.141186\n",
      "Step 926: Generator Loss: 0.136536\n",
      "Step 927: Generator Loss: 0.138833\n",
      "Step 928: Generator Loss: 0.140475\n",
      "Step 929: Generator Loss: 0.137551\n",
      "Step 930: Generator Loss: 0.136807\n",
      "Step 931: Generator Loss: 0.138311\n",
      "Step 932: Generator Loss: 0.139269\n",
      "Step 933: Generator Loss: 0.136062\n",
      "Step 934: Generator Loss: 0.136242\n",
      "Step 935: Generator Loss: 0.141523\n",
      "Step 936: Generator Loss: 0.137377\n",
      "Step 937: Generator Loss: 0.137445\n",
      "Step 938: Generator Loss: 0.145756\n",
      "Step 939: Generator Loss: 0.140124\n",
      "Step 940: Generator Loss: 0.139403\n",
      "Step 941: Generator Loss: 0.133666\n",
      "Step 942: Generator Loss: 0.132695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 943: Generator Loss: 0.136243\n",
      "Step 944: Generator Loss: 0.138281\n",
      "Step 945: Generator Loss: 0.136646\n",
      "Step 946: Generator Loss: 0.133406\n",
      "Step 947: Generator Loss: 0.133212\n",
      "Step 948: Generator Loss: 0.136317\n",
      "Step 949: Generator Loss: 0.136267\n",
      "Step 950: Generator Loss: 0.133938\n",
      "Step 951: Generator Loss: 0.132983\n",
      "Step 952: Generator Loss: 0.136854\n",
      "Step 953: Generator Loss: 0.134116\n",
      "Step 954: Generator Loss: 0.134556\n",
      "Step 955: Generator Loss: 0.133684\n",
      "Step 956: Generator Loss: 0.132151\n",
      "Step 957: Generator Loss: 0.135623\n",
      "Step 958: Generator Loss: 0.132383\n",
      "Step 959: Generator Loss: 0.138864\n",
      "Step 960: Generator Loss: 0.138889\n",
      "Step 961: Generator Loss: 0.135500\n",
      "Step 962: Generator Loss: 0.133312\n",
      "Step 963: Generator Loss: 0.131077\n",
      "Step 964: Generator Loss: 0.137684\n",
      "Step 965: Generator Loss: 0.138052\n",
      "Step 966: Generator Loss: 0.134252\n",
      "Step 967: Generator Loss: 0.139598\n",
      "Step 968: Generator Loss: 0.135644\n",
      "Step 969: Generator Loss: 0.134481\n",
      "Step 970: Generator Loss: 0.131606\n",
      "Step 971: Generator Loss: 0.130846\n",
      "Step 972: Generator Loss: 0.133899\n",
      "Step 973: Generator Loss: 0.136524\n",
      "Step 974: Generator Loss: 0.127665\n",
      "Step 975: Generator Loss: 0.134876\n",
      "Step 976: Generator Loss: 0.139393\n",
      "Step 977: Generator Loss: 0.128501\n",
      "Step 978: Generator Loss: 0.132245\n",
      "Step 979: Generator Loss: 0.129788\n",
      "Step 980: Generator Loss: 0.135072\n",
      "Step 981: Generator Loss: 0.131707\n",
      "Step 982: Generator Loss: 0.130282\n",
      "Step 983: Generator Loss: 0.132110\n",
      "Step 984: Generator Loss: 0.131087\n",
      "Step 985: Generator Loss: 0.132903\n",
      "Step 986: Generator Loss: 0.129466\n",
      "Step 987: Generator Loss: 0.125810\n",
      "Step 988: Generator Loss: 0.130211\n",
      "Step 989: Generator Loss: 0.131365\n",
      "Step 990: Generator Loss: 0.128677\n",
      "Step 991: Generator Loss: 0.128681\n",
      "Step 992: Generator Loss: 0.133094\n",
      "Step 993: Generator Loss: 0.128045\n",
      "Step 994: Generator Loss: 0.127098\n",
      "Step 995: Generator Loss: 0.130920\n",
      "Step 996: Generator Loss: 0.131233\n",
      "Step 997: Generator Loss: 0.131714\n",
      "Step 998: Generator Loss: 0.131697\n",
      "Step 999: Generator Loss: 0.129098\n",
      "Step 1000: Generator Loss: 0.130569\n",
      "Starting actual training\n",
      "Step 1: Generator Loss: 1.499137, Disc SCI Loss: 1.396130, Disc gvr Loss: 1.401882\n",
      "Step 2: Generator Loss: 9.643794, Disc SCI Loss: 1.391921, Disc gvr Loss: 0.681786\n",
      "Step 3: Generator Loss: 14.495475, Disc SCI Loss: 1.380584, Disc gvr Loss: 0.677117\n",
      "Step 4: Generator Loss: 17.549124, Disc SCI Loss: 1.372966, Disc gvr Loss: 0.667029\n",
      "Step 5: Generator Loss: 18.667591, Disc SCI Loss: 1.359527, Disc gvr Loss: 0.653118\n",
      "Step 6: Generator Loss: 19.081825, Disc SCI Loss: 1.348960, Disc gvr Loss: 0.657403\n",
      "Step 7: Generator Loss: 19.814411, Disc SCI Loss: 1.341133, Disc gvr Loss: 0.647996\n",
      "Step 8: Generator Loss: 19.893011, Disc SCI Loss: 1.326883, Disc gvr Loss: 0.632211\n",
      "Step 9: Generator Loss: 20.152527, Disc SCI Loss: 1.319992, Disc gvr Loss: 0.632018\n",
      "Step 10: Generator Loss: 20.424715, Disc SCI Loss: 1.285428, Disc gvr Loss: 0.621182\n",
      "Finished Training\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fd93460fd6f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Finished Training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# test SCI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m \u001b[0mx_norm\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisc_SCI_normal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ce 3a\\cs 480\\onlinegrooming\\venv\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36mtodense\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    847\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mshares\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m         \"\"\"\n\u001b[1;32m--> 849\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ce 3a\\cs 480\\onlinegrooming\\venv\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    963\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ce 3a\\cs 480\\onlinegrooming\\venv\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1185\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1187\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    sess.run([iter_norm.initializer, iter_susp.initializer], feed_dict={ x_norm: X_train_norm.todense(), x_susp: X_train_susp.todense()})\n",
    "    \n",
    "    print('Pretraining of generator starting.')\n",
    "    for i in range(1, num_steps*100+1):\n",
    "        z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
    "        # Train\n",
    "#         feed_dict = {disc_input: batch_x, gen_input: z}\n",
    "        feed_dict = {gen_input: z}\n",
    "        _, glpre = sess.run([train_gen_pre, gen_loss_pre], feed_dict=feed_dict)\n",
    "        print('Step %i: Generator Loss: %f' % (i, glpre))\n",
    "    \n",
    "#     sess.run([iter_norm.initializer, iter_susp.initializer], feed_dict={ x_norm: X_train_norm.todense(), x_susp: X_train_susp.todense()})\n",
    "    print('Starting actual training')\n",
    "    for i in range(1, num_steps+1):\n",
    "        # Prepare Data\n",
    "        # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "#         batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "#         batch_x_norm, _ = next_batch(batch_size, X_train_norm, y_train_norm)\n",
    "#         batch_x_susp, _ = next_batch(batch_size, X_train_susp, y_train_susp)\n",
    "#         print(batch_x_norm.shape)\n",
    "#         print(batch_x_susp.shape)\n",
    "        # Generate noise to feed to the generator\n",
    "        z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
    "        # Train\n",
    "#         feed_dict = {disc_input: batch_x, gen_input: z}\n",
    "        feed_dict = {gen_input: z}\n",
    "        _, _, _, gl, dSCIl, dgvrl = sess.run([train_gen, train_disc_SCI, train_disc_gvr, gen_loss, disc_SCI_loss, disc_gvr_loss],\n",
    "                                feed_dict=feed_dict)\n",
    "#         if i % 1000 == 0 or i == 1:\n",
    "        print('Step %i: Generator Loss: %f, Disc SCI Loss: %f, Disc gvr Loss: %f' % (i, gl, dSCIl, dgvrl))\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    # test SCI\n",
    "    sess.run(iter_norm.initializer, feed_dict={ x_norm: X_test.todense()})\n",
    "    y_pred = sess.run(disc_SCI_normal)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "#     # Generate images from noise, using the generator network.\n",
    "#     f, a = plt.subplots(4, 10, figsize=(10, 4))\n",
    "#     for i in range(10):\n",
    "#         # Noise input.\n",
    "#         z = np.random.uniform(-1., 1., size=[4, noise_dim])\n",
    "#         g = sess.run([gen_sample], feed_dict={gen_input: z})\n",
    "#         g = np.reshape(g, newshape=(4, 28, 28, 1))\n",
    "#         # Reverse colours for better display\n",
    "#         g = -1 * (g - 1)\n",
    "#         for j in range(4):\n",
    "#             # Generate image from noise. Extend to 3 channels for matplot figure.\n",
    "#             img = np.reshape(np.repeat(g[j][:, :, np.newaxis], 3, axis=2),\n",
    "#                              newshape=(28, 28, 3))\n",
    "#             a[j][i].imshow(img)\n",
    "\n",
    "#     f.show()\n",
    "#     plt.draw()\n",
    "#     plt.waitforbuttonpress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are getting a diverging GAN error, according to https://github.com/soumith/ganhacks/issues/14, this may be because\n",
    "\n",
    "Pretraining the generator with real susp conversations is not working since in training, noise is used as generator's input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
