{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the SVM\n",
    "Here we will aim to represent the conversations using Bag-Of-Words (BOW) with a TF-IDF weighing scheme and then build our SVM Suspicious Conversations Identifier (SCI).\n",
    "\n",
    "First we read in the training data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_labels_dict(data_path):\n",
    "    labels_dict = {}\n",
    "    with open(data_path + 'sci_labels.csv', 'r') as f:\n",
    "        file = csv.reader(f)\n",
    "        for row in file:\n",
    "            labels_dict[row[0]] = row[1]\n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def get_features_labels(root, labels_dict):\n",
    "    corpus = [] # each row is a string formed from all messages in a conversations\n",
    "    labels = [] # each row is 0 or 1, corresponds to label for same row in corpus\n",
    "\n",
    "    for conversation in root:\n",
    "        string = \" \"\n",
    "        for message in conversation:\n",
    "            text = message.find('text').text\n",
    "            if text is not None:\n",
    "                string = string + \"\\r\\n\" + text \n",
    "        corpus.append(string)\n",
    "        labels.append(int(labels_dict[conversation.get('id')]))\n",
    "    return corpus, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../../data/svm_training_data/'\n",
    "training_xml = ET.parse(train_data_path + 'training_data.xml')\n",
    "train_root = training_xml.getroot()\n",
    "\n",
    "test_data_path = '../../data/svm_test_data/'\n",
    "test_data_src = '../../data/pan12-sexual-predator-identification-test-corpus-2012-05-21/'\n",
    "test_xml = ET.parse(test_data_src + 'pan12-sexual-predator-identification-test-corpus-2012-05-17.xml')\n",
    "test_root = test_xml.getroot()\n",
    "\n",
    "train_corpus, train_labels = get_features_labels(train_root, get_labels_dict(train_data_path))\n",
    "test_corpus, test_labels = get_features_labels(test_root, get_labels_dict(test_data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now represent all conversations using BOW with TF-IDF weighing scheme.\n",
    "- [] Customize Vectorizer Parameters like normailize\n",
    "- [] Use hashing vectorization to save space and see if performance affected (https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_corpus)\n",
    "X_test = vectorizer.transform(test_corpus)\n",
    "\n",
    "X_train = scipy.sparse.csr_matrix(X_train)\n",
    "y_train = np.array(train_labels)\n",
    "X_test = scipy.sparse.csr_matrix(X_test)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=87)\n",
    "# print(\"Train data shape:{}\\r\\nTest data shape:{}\".format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build the SVM and do cross validation to explore the accuracy of each kernel and hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear, c=1, Accuracy: 0.9960551616975819\n",
      "linear, c=10, Accuracy: 0.9956471834144942\n",
      "linear, c=100, Accuracy: 0.9956471834144942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing linear kernel SVM: C=1, Acc=0.9960551616975819\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import heapq\n",
    "import operator\n",
    "import numpy as np\n",
    "\n",
    "num_fold = 10\n",
    "k_fold = KFold(num_fold, True, 1)\n",
    "kernel = 'linear'\n",
    "acc = []\n",
    "\n",
    "for coef_c in [1, 10, 100]:\n",
    "    acc_arr = np.zeros(num_fold)\n",
    "    ind = 0\n",
    "    for train_rows, val_rows in k_fold.split(X_train):\n",
    "        model = svm.SVC(kernel=kernel, C=coef_c, gamma='auto', random_state=0)\n",
    "        model.fit(X_train[train_rows], y_train[train_rows])\n",
    "        pred_y = model.predict(X_train[val_rows])\n",
    "        acc_arr[ind] = metrics.accuracy_score(y_train[val_rows], pred_y)\n",
    "        ind += 1\n",
    "    acc.append([coef_c, np.mean(acc_arr)])\n",
    "    print(\"{}, c={}, Accuracy: {}\".format(kernel, coef_c, acc[len(acc)-1][1]))\n",
    "plt.plot([i[0] for i in acc], [i[1] for i in acc])\n",
    "plt.title(\"Performance of {} SVM\".format(kernel))\n",
    "plt.xlabel(\"C value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# plt.savefig('../output/As1_Qn4.2_' + kernel + '_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\") + '.png')\n",
    "plt.show()\n",
    "best = heapq.nlargest(1, acc, key=operator.itemgetter(1))[0]\n",
    "print(\"Best performing linear kernel SVM: C={}, Acc={}\".format(best[0], best[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the best linear kernel model, let us test against our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9856054355113197\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel='linear', C=best[0], gamma='auto', random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "pred_y = model.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For linear kernel SVM with C coeficient of 1, we are getting an accuracy of 0.98561!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "\n",
    "# save the model to the models folder\n",
    "filename = '../../models/SCI_SVM_' + \"{:.2f}_\".format(metrics.accuracy_score(y_test, pred_y)) + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\") + '.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
